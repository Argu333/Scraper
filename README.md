# ğŸ•·ï¸ Web Scraper & Crawler in Python

A Python-based web scraper and crawler designed to extract structured data from various websites â€” including those with anti-scraping techniques like custom headers and CSRF protection.

---

## ğŸŒ Target Websites

- **[Books to Scrape](https://books.toscrape.com)**  
- **[Scraping Course â€“ CSRF Protected Login](https://www.scrapingcourse.com/login/csrf)**  
- **[Scrape This Site â€“ Advanced Headers Challenge](https://www.scrapethissite.com/pages/advanced/?gotcha=headers)**  

---

## ğŸ› ï¸ Features

- âœ… Custom headers to bypass basic anti-bot detection  
- âœ… Automatic pagination support  
- âœ… CSRF token retrieval and session-based login handling  
- âœ… Output data to JSON 

---

## ğŸ“ Project Structure

```bash
Scraper/
â”œâ”€â”€ Sync/                     # Synchronous scraping modules
â”‚   â”œâ”€â”€ Categories.py         # Gets all the books categories
â”‚   â”œâ”€â”€ NamePrice.py          # Extracts book names and prices
â”‚   â””â”€â”€ Total.py              # Extracts book names and prices as per their categories
â”‚
â”œâ”€â”€ async.py                  # Asynchronous scraping module
â”œâ”€â”€ header.py                 # Manages headers/user-agents
â”œâ”€â”€ Login.py                  # Handles login/authentication
â””â”€â”€ Scrape.json               # Scraping output for "async.py"
```
---

## ğŸ§° Tech Stack

- Python 3.11.9
- [requests](https://pypi.org/project/requests/) â€“ HTTP requests
- [BeautifulSoup](https://pypi.org/project/beautifulsoup4/) â€“ HTML parsing
- asyncio, aiohttp
- json

---

## âš™ï¸ Setup Instructions

1. **Clone the Repository**

```bash
git clone https://github.com/Argu333/Scraper.git
cd Scraper
```
2. **Install the used libraries (if not installed)**
```bash
pip install requests
pip install beautifulsoup4
pip install aiohttp
```
